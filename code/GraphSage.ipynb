{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13900490,
     "sourceType": "datasetVersion",
     "datasetId": 8856110
    }
   ],
   "dockerImageVersionId": 31193,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --quiet torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:39.216024Z",
     "iopub.execute_input": "2025-12-03T14:46:39.216307Z",
     "iopub.status.idle": "2025-12-03T14:46:46.599629Z",
     "shell.execute_reply.started": "2025-12-03T14:46:39.216291Z",
     "shell.execute_reply": "2025-12-03T14:46:46.598934Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import gc\n",
    "from torch_geometric.transforms import ToUndirected, RandomNodeSplit\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:56.351548Z",
     "iopub.execute_input": "2025-12-03T14:46:56.352032Z",
     "iopub.status.idle": "2025-12-03T14:46:56.447725Z",
     "shell.execute_reply.started": "2025-12-03T14:46:56.352005Z",
     "shell.execute_reply": "2025-12-03T14:46:56.447162Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load/download OGB-MAG (metapath2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = OGB_MAG(root=\"data/OGB\", preprocess=\"metapath2vec\", transform=ToUndirected())\n",
    "data = dataset[0]\n",
    "print(\"Original node types:\", data.node_types)\n",
    "print(\"Original edge types:\", data.edge_types)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:56.448430Z",
     "iopub.execute_input": "2025-12-03T14:46:56.448672Z",
     "iopub.status.idle": "2025-12-03T14:47:44.878503Z",
     "shell.execute_reply.started": "2025-12-03T14:46:56.448644Z",
     "shell.execute_reply": "2025-12-03T14:47:44.877667Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subgraph Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of paper nodes we decided to keep (centered set)\n",
    "num_papers = 60000\n",
    "paper_ids = torch.arange(num_papers)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:48.654776Z",
     "iopub.execute_input": "2025-12-03T19:44:48.655494Z",
     "iopub.status.idle": "2025-12-03T19:44:48.659223Z",
     "shell.execute_reply.started": "2025-12-03T19:44:48.655470Z",
     "shell.execute_reply": "2025-12-03T19:44:48.658633Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1-Hop Heterogeneous Subgraph Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Build nodes_to_keep (papers + 1-hop neighbors)\n",
    "nodes_to_keep = {'paper': paper_ids}\n",
    "for (src, rel, dst), edge_index in data.edge_index_dict.items():\n",
    "    ei = edge_index\n",
    "    # neighbors going out from papers\n",
    "    if src == 'paper':\n",
    "        mask = torch.isin(ei[0], paper_ids)\n",
    "        if mask.any():\n",
    "            dst_nodes = torch.unique(ei[1, mask])\n",
    "            if dst in nodes_to_keep:\n",
    "                nodes_to_keep[dst] = torch.unique(torch.cat([nodes_to_keep[dst], dst_nodes]))\n",
    "            else:\n",
    "                nodes_to_keep[dst] = dst_nodes\n",
    "    # neighbors pointing into papers\n",
    "    if dst == 'paper':\n",
    "        mask = torch.isin(ei[1], paper_ids)\n",
    "        if mask.any():\n",
    "            src_nodes = torch.unique(ei[0, mask])\n",
    "            if src in nodes_to_keep:\n",
    "                nodes_to_keep[src] = torch.unique(torch.cat([nodes_to_keep[src], src_nodes]))\n",
    "            else:\n",
    "                nodes_to_keep[src] = src_nodes\n",
    "\n",
    "\n",
    "# Create 1-hop heterogeneous subgraph\n",
    "data_sub = data.subgraph(nodes_to_keep)\n",
    "print(\"1-hop heterogeneous subgraph created.\")\n",
    "print(\"Num papers:\", data_sub[\"paper\"].num_nodes)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:48.989650Z",
     "iopub.execute_input": "2025-12-03T19:44:48.990080Z",
     "iopub.status.idle": "2025-12-03T19:44:53.557764Z",
     "shell.execute_reply.started": "2025-12-03T19:44:48.990060Z",
     "shell.execute_reply": "2025-12-03T19:44:53.557023Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Venue Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y = data_sub[\"paper\"].y\n",
    "unique, counts = torch.unique(y, return_counts=True)\n",
    "\n",
    "df_venues = pd.DataFrame({\n",
    "    \"venue_id\": unique.cpu().tolist(),\n",
    "    \"count\": counts.cpu().tolist()\n",
    "})\n",
    "df_venues.to_csv(\"venue_distribution.csv\", index=False)\n",
    "print(\"Save venue_distribution.csv\")\n",
    "\n",
    "num_classes = int(y.max().item() + 1)\n",
    "print(\"Number of venues:\", num_classes)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:53.559046Z",
     "iopub.execute_input": "2025-12-03T19:44:53.559303Z",
     "iopub.status.idle": "2025-12-03T19:44:53.575059Z",
     "shell.execute_reply.started": "2025-12-03T19:44:53.559285Z",
     "shell.execute_reply": "2025-12-03T19:44:53.574464Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train/Validation/Test Split and Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_nodes = data_sub[\"paper\"].num_nodes\n",
    "num_val = int(num_nodes * 0.15)   \n",
    "num_test = int(num_nodes * 0.15)  \n",
    "\n",
    "# Apply a random node split for train/val/test\n",
    "split_transform = RandomNodeSplit(split=\"train_rest\",num_val=num_val,num_test=num_test)\n",
    "data_sub = split_transform(data_sub)\n",
    "\n",
    "print(\"Train =\", data_sub[\"paper\"].train_mask.sum().item())\n",
    "print(\"Val   =\", data_sub[\"paper\"].val_mask.sum().item())\n",
    "print(\"Test  =\", data_sub[\"paper\"].test_mask.sum().item())\n",
    "\n",
    "data_sub = data_sub.to(device)\n",
    "\n",
    "# Extract node features and edge indices\n",
    "x_dict = data_sub.x_dict\n",
    "edge_index_dict = data_sub.edge_index_dict\n",
    "\n",
    "# Extract labels and masks for papers\n",
    "y = data_sub['paper'].y\n",
    "train_mask = data_sub['paper'].train_mask\n",
    "val_mask = data_sub['paper'].val_mask\n",
    "test_mask = data_sub['paper'].test_mask\n",
    "\n",
    "# Get the number of features for paper nodes\n",
    "num_features = x_dict['paper'].shape[1]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:49:25.223454Z",
     "iopub.execute_input": "2025-12-03T19:49:25.223998Z",
     "iopub.status.idle": "2025-12-03T19:49:25.438043Z",
     "shell.execute_reply.started": "2025-12-03T19:49:25.223972Z",
     "shell.execute_reply": "2025-12-03T19:49:25.437449Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GraphSAGE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GraphSAGEEnc(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, aggr='mean'):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels, aggr=aggr)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels, aggr=aggr)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        return h\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.905927Z",
     "iopub.execute_input": "2025-12-03T14:47:49.906161Z",
     "iopub.status.idle": "2025-12-03T14:47:49.910577Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.906136Z",
     "shell.execute_reply": "2025-12-03T14:47:49.909955Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics Computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(logits, y_true):\n",
    "    preds = logits.argmax(dim=-1).cpu()\n",
    "    y_true = y_true.cpu()\n",
    "    \n",
    "    accuracy = (preds == y_true).sum().item() / y_true.size(0)\n",
    "    f1 = f1_score(y_true, preds, average=\"macro\")\n",
    "    \n",
    "    y_prob = torch.softmax(logits, dim=-1).cpu()\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "    \n",
    "    return accuracy, f1, auc\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.911317Z",
     "iopub.execute_input": "2025-12-03T14:47:49.911631Z",
     "iopub.status.idle": "2025-12-03T14:47:49.922756Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.911611Z",
     "shell.execute_reply": "2025-12-03T14:47:49.922196Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Heterogeneous GraphSAGE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCHS = 200\n",
    "AGGREGATIONS = [\"mean\", \"sum\"]\n",
    "\n",
    "for aggr in AGGREGATIONS:\n",
    "    print(f\"\\n=== Training heterogeneous GraphSAGE with aggr={aggr} ===\")\n",
    "    base_model = GraphSAGEEnc(num_features, 128, 128, aggr=aggr)\n",
    "    model_hetero = to_hetero(base_model, data_sub.metadata(), aggr=aggr).to(device)\n",
    "    head = nn.Linear(128, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(list(model_hetero.parameters()) + list(head.parameters()), lr=0.001)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model_hetero.train()\n",
    "        head.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h_dict = model_hetero(x_dict, edge_index_dict)\n",
    "        logits = head(h_dict[\"paper\"])\n",
    "        loss = F.cross_entropy(logits[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation \n",
    "        model_hetero.eval()\n",
    "        head.eval()\n",
    "        with torch.no_grad():\n",
    "            train_acc, train_f1, train_auc = compute_metrics(logits[train_mask], y[train_mask])\n",
    "            val_acc, val_f1, val_auc = compute_metrics(logits[val_mask], y[val_mask])\n",
    "\n",
    "        \n",
    "        metrics.append([\n",
    "            epoch,\n",
    "            float(loss.item()),\n",
    "            train_acc, train_f1, train_auc,\n",
    "            val_acc, val_f1, val_auc\n",
    "        ])\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | Loss={loss:.4f} | \"\n",
    "                f\"Train Acc={train_acc:.4f} F1={train_f1:.4f} AUC={train_auc:.4f} | \"\n",
    "                f\"Val Acc={val_acc:.4f} F1={val_f1:.4f} AUC={val_auc:.4f}\"\n",
    "            )\n",
    "\n",
    "    # Save models\n",
    "    torch.save(model_hetero.state_dict(), f\"model_{aggr}.pth\")\n",
    "    torch.save(head.state_dict(), f\"head_{aggr}.pth\")\n",
    "    print(f\"Models saved for aggr={aggr}.\")\n",
    "\n",
    "    # Save CSV\n",
    "    df_metrics = pd.DataFrame(\n",
    "        metrics,\n",
    "        columns=[\n",
    "            \"epoch\",\n",
    "            \"loss\",\n",
    "            \"train_acc\", \"train_f1\", \"train_auc\",\n",
    "            \"val_acc\", \"val_f1\", \"val_auc\"\n",
    "        ]\n",
    "    )\n",
    "    df_metrics.to_csv(f\"metrics_{aggr}.csv\", index=False)\n",
    "    print(f\"Metrics saved: metrics_{aggr}.csv\")\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    del model_hetero, head, optimizer, metrics, logits\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.923521Z",
     "iopub.execute_input": "2025-12-03T14:47:49.923877Z",
     "iopub.status.idle": "2025-12-03T19:34:44.839438Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.923852Z",
     "shell.execute_reply": "2025-12-03T19:34:44.838873Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for aggr in AGGREGATIONS:\n",
    "    print(f\"\\n=== Testing models using the aggregation {aggr} ===\")\n",
    "    \n",
    "    base_model = GraphSAGEEnc(num_features, 128, 128, aggr=aggr)\n",
    "    model_hetero = to_hetero(base_model, data_sub.metadata(), aggr=aggr).to(device)\n",
    "    head = nn.Linear(128, num_classes).to(device)\n",
    "    \n",
    "    # Load Weights of the models\n",
    "    model_hetero.load_state_dict(torch.load(f\"/kaggle/working/model_{aggr}.pth\"))\n",
    "    head.load_state_dict(torch.load(f\"/kaggle/working/head_{aggr}.pth\"))\n",
    "    \n",
    "    model_hetero.eval()\n",
    "    head.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h_dict = model_hetero(x_dict, edge_index_dict)\n",
    "        logits = head(h_dict[\"paper\"])\n",
    "        \n",
    "        # Calculate Metrics\n",
    "        test_acc, test_f1, test_auc = compute_metrics(logits[test_mask], y[test_mask])\n",
    "        \n",
    "    print(f\"Test Acc={test_acc:.4f} | Test F1={test_f1:.4f} | Test AUC={test_auc:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results[aggr] = {\n",
    "        \"acc\": test_acc,\n",
    "        \"f1\": test_f1,\n",
    "        \"auc\": test_auc\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ]
}
