{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13900490,
     "sourceType": "datasetVersion",
     "datasetId": 8856110
    }
   ],
   "dockerImageVersionId": 31193,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --quiet torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:39.216024Z",
     "iopub.execute_input": "2025-12-03T14:46:39.216307Z",
     "iopub.status.idle": "2025-12-03T14:46:46.599629Z",
     "shell.execute_reply.started": "2025-12-03T14:46:39.216291Z",
     "shell.execute_reply": "2025-12-03T14:46:46.598934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/10.2 MB\u001B[0m \u001B[31m63.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/4.9 MB\u001B[0m \u001B[31m98.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m35.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m891.8/891.8 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.7/63.7 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m22.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[?25h",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import gc\n",
    "from torch_geometric.transforms import ToUndirected, RandomNodeSplit\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:56.351548Z",
     "iopub.execute_input": "2025-12-03T14:46:56.352032Z",
     "iopub.status.idle": "2025-12-03T14:46:56.447725Z",
     "shell.execute_reply.started": "2025-12-03T14:46:56.352005Z",
     "shell.execute_reply": "2025-12-03T14:46:56.447162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Device: cuda\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load/download OGB-MAG (metapath2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = OGB_MAG(root=\"data/OGB\", preprocess=\"metapath2vec\", transform=ToUndirected())\n",
    "data = dataset[0]\n",
    "print(\"Original node types:\", data.node_types)\n",
    "print(\"Original edge types:\", data.edge_types)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:46:56.448430Z",
     "iopub.execute_input": "2025-12-03T14:46:56.448672Z",
     "iopub.status.idle": "2025-12-03T14:47:44.878503Z",
     "shell.execute_reply.started": "2025-12-03T14:46:56.448644Z",
     "shell.execute_reply": "2025-12-03T14:47:44.877667Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/mag.zip\nExtracting data/OGB/mag/raw/mag.zip\nDownloading https://data.pyg.org/datasets/mag_metapath2vec_emb.zip\nExtracting data/OGB/mag/raw/mag_metapath2vec_emb.zip\nProcessing...\nDone!\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Original node types: ['paper', 'author', 'institution', 'field_of_study']\nOriginal edge types: [('author', 'affiliated_with', 'institution'), ('author', 'writes', 'paper'), ('paper', 'cites', 'paper'), ('paper', 'has_topic', 'field_of_study'), ('institution', 'rev_affiliated_with', 'author'), ('paper', 'rev_writes', 'author'), ('field_of_study', 'rev_has_topic', 'paper')]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subgraph Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Number of paper nodes we decided to keep (centered set)\n",
    "num_papers = 60000\n",
    "paper_ids = torch.arange(num_papers)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:48.654776Z",
     "iopub.execute_input": "2025-12-03T19:44:48.655494Z",
     "iopub.status.idle": "2025-12-03T19:44:48.659223Z",
     "shell.execute_reply.started": "2025-12-03T19:44:48.655470Z",
     "shell.execute_reply": "2025-12-03T19:44:48.658633Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1-Hop Heterogeneous Subgraph Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Build nodes_to_keep (papers + 1-hop neighbors)\n",
    "nodes_to_keep = {'paper': paper_ids}\n",
    "for (src, rel, dst), edge_index in data.edge_index_dict.items():\n",
    "    ei = edge_index\n",
    "    # neighbors going out from papers\n",
    "    if src == 'paper':\n",
    "        mask = torch.isin(ei[0], paper_ids)\n",
    "        if mask.any():\n",
    "            dst_nodes = torch.unique(ei[1, mask])\n",
    "            if dst in nodes_to_keep:\n",
    "                nodes_to_keep[dst] = torch.unique(torch.cat([nodes_to_keep[dst], dst_nodes]))\n",
    "            else:\n",
    "                nodes_to_keep[dst] = dst_nodes\n",
    "    # neighbors pointing into papers\n",
    "    if dst == 'paper':\n",
    "        mask = torch.isin(ei[1], paper_ids)\n",
    "        if mask.any():\n",
    "            src_nodes = torch.unique(ei[0, mask])\n",
    "            if src in nodes_to_keep:\n",
    "                nodes_to_keep[src] = torch.unique(torch.cat([nodes_to_keep[src], src_nodes]))\n",
    "            else:\n",
    "                nodes_to_keep[src] = src_nodes\n",
    "\n",
    "\n",
    "# Create 1-hop heterogeneous subgraph\n",
    "data_sub = data.subgraph(nodes_to_keep)\n",
    "print(\"1-hop heterogeneous subgraph created.\")\n",
    "print(\"Num papers:\", data_sub[\"paper\"].num_nodes)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:48.989650Z",
     "iopub.execute_input": "2025-12-03T19:44:48.990080Z",
     "iopub.status.idle": "2025-12-03T19:44:53.557764Z",
     "shell.execute_reply.started": "2025-12-03T19:44:48.990060Z",
     "shell.execute_reply": "2025-12-03T19:44:53.557023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Subgrafo 1-hop heterogéneo criado.\nNum papers: 398144\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Venue Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y = data_sub[\"paper\"].y\n",
    "unique, counts = torch.unique(y, return_counts=True)\n",
    "\n",
    "df_venues = pd.DataFrame({\n",
    "    \"venue_id\": unique.cpu().tolist(),\n",
    "    \"count\": counts.cpu().tolist()\n",
    "})\n",
    "df_venues.to_csv(\"venue_distribution.csv\", index=False)\n",
    "print(\"Save venue_distribution.csv\")\n",
    "\n",
    "num_classes = int(y.max().item() + 1)\n",
    "print(\"Number of venues:\", num_classes)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:44:53.559046Z",
     "iopub.execute_input": "2025-12-03T19:44:53.559303Z",
     "iopub.status.idle": "2025-12-03T19:44:53.575059Z",
     "shell.execute_reply.started": "2025-12-03T19:44:53.559285Z",
     "shell.execute_reply": "2025-12-03T19:44:53.574464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Guardado venue_distribution.csv\nNúmero de venues: 349\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train/Validation/Test Split and Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_nodes = data_sub[\"paper\"].num_nodes\n",
    "num_val = int(num_nodes * 0.15)   \n",
    "num_test = int(num_nodes * 0.15)  \n",
    "\n",
    "# Apply a random node split for train/val/test\n",
    "split_transform = RandomNodeSplit(split=\"train_rest\",num_val=num_val,num_test=num_test)\n",
    "data_sub = split_transform(data_sub)\n",
    "\n",
    "print(\"Train =\", data_sub[\"paper\"].train_mask.sum().item())\n",
    "print(\"Val   =\", data_sub[\"paper\"].val_mask.sum().item())\n",
    "print(\"Test  =\", data_sub[\"paper\"].test_mask.sum().item())\n",
    "\n",
    "data_sub = data_sub.to(device)\n",
    "\n",
    "# Extract node features and edge indices\n",
    "x_dict = data_sub.x_dict\n",
    "edge_index_dict = data_sub.edge_index_dict\n",
    "\n",
    "# Extract labels and masks for papers\n",
    "y = data_sub['paper'].y\n",
    "train_mask = data_sub['paper'].train_mask\n",
    "val_mask = data_sub['paper'].val_mask\n",
    "test_mask = data_sub['paper'].test_mask\n",
    "\n",
    "# Get the number of features for paper nodes\n",
    "num_features = x_dict['paper'].shape[1]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:49:25.223454Z",
     "iopub.execute_input": "2025-12-03T19:49:25.223998Z",
     "iopub.status.idle": "2025-12-03T19:49:25.438043Z",
     "shell.execute_reply.started": "2025-12-03T19:49:25.223972Z",
     "shell.execute_reply": "2025-12-03T19:49:25.437449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Train = 298609\nVal   = 59721\nTest  = 39814\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GraphSAGE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GraphSAGEEnc(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, aggr='mean'):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels, aggr=aggr)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels, aggr=aggr)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        return h\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.905927Z",
     "iopub.execute_input": "2025-12-03T14:47:49.906161Z",
     "iopub.status.idle": "2025-12-03T14:47:49.910577Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.906136Z",
     "shell.execute_reply": "2025-12-03T14:47:49.909955Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics Computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(logits, y_true):\n",
    "    preds = logits.argmax(dim=-1).cpu()\n",
    "    y_true = y_true.cpu()\n",
    "    \n",
    "    accuracy = (preds == y_true).sum().item() / y_true.size(0)\n",
    "    f1 = f1_score(y_true, preds, average=\"macro\")\n",
    "    \n",
    "    y_prob = torch.softmax(logits, dim=-1).cpu()\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob, multi_class=\"ovr\")\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "    \n",
    "    return accuracy, f1, auc\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.911317Z",
     "iopub.execute_input": "2025-12-03T14:47:49.911631Z",
     "iopub.status.idle": "2025-12-03T14:47:49.922756Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.911611Z",
     "shell.execute_reply": "2025-12-03T14:47:49.922196Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Heterogeneous GraphSAGE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCHS = 200\n",
    "AGGREGATIONS = [\"mean\", \"sum\"]\n",
    "\n",
    "for aggr in AGGREGATIONS:\n",
    "    print(f\"\\n=== Training heterogeneous GraphSAGE with aggr={aggr} ===\")\n",
    "    base_model = GraphSAGEEnc(num_features, 128, 128, aggr=aggr)\n",
    "    model_hetero = to_hetero(base_model, data_sub.metadata(), aggr=aggr).to(device)\n",
    "    head = nn.Linear(128, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(list(model_hetero.parameters()) + list(head.parameters()), lr=0.001)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model_hetero.train()\n",
    "        head.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h_dict = model_hetero(x_dict, edge_index_dict)\n",
    "        logits = head(h_dict[\"paper\"])\n",
    "        loss = F.cross_entropy(logits[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluation \n",
    "        model_hetero.eval()\n",
    "        head.eval()\n",
    "        with torch.no_grad():\n",
    "            train_acc, train_f1, train_auc = compute_metrics(logits[train_mask], y[train_mask])\n",
    "            val_acc, val_f1, val_auc = compute_metrics(logits[val_mask], y[val_mask])\n",
    "\n",
    "        \n",
    "        metrics.append([\n",
    "            epoch,\n",
    "            float(loss.item()),\n",
    "            train_acc, train_f1, train_auc,\n",
    "            val_acc, val_f1, val_auc\n",
    "        ])\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | Loss={loss:.4f} | \"\n",
    "                f\"Train Acc={train_acc:.4f} F1={train_f1:.4f} AUC={train_auc:.4f} | \"\n",
    "                f\"Val Acc={val_acc:.4f} F1={val_f1:.4f} AUC={val_auc:.4f}\"\n",
    "            )\n",
    "\n",
    "    # Save models\n",
    "    torch.save(model_hetero.state_dict(), f\"model_{aggr}.pth\")\n",
    "    torch.save(head.state_dict(), f\"head_{aggr}.pth\")\n",
    "    print(f\"Models saved for aggr={aggr}.\")\n",
    "\n",
    "    # Save CSV\n",
    "    df_metrics = pd.DataFrame(\n",
    "        metrics,\n",
    "        columns=[\n",
    "            \"epoch\",\n",
    "            \"loss\",\n",
    "            \"train_acc\", \"train_f1\", \"train_auc\",\n",
    "            \"val_acc\", \"val_f1\", \"val_auc\"\n",
    "        ]\n",
    "    )\n",
    "    df_metrics.to_csv(f\"metrics_{aggr}.csv\", index=False)\n",
    "    print(f\"Metrics saved: metrics_{aggr}.csv\")\n",
    "\n",
    "    # Cleanup to free memory\n",
    "    del model_hetero, head, optimizer, metrics, logits\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T14:47:49.923521Z",
     "iopub.execute_input": "2025-12-03T14:47:49.923877Z",
     "iopub.status.idle": "2025-12-03T19:34:44.839438Z",
     "shell.execute_reply.started": "2025-12-03T14:47:49.923852Z",
     "shell.execute_reply": "2025-12-03T19:34:44.838873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\n=== Treino GraphSAGE heterogéneo com aggr=mean ===\nEpoch 010 | Loss=5.0618 | Train Acc=0.0967 F1=0.0025 AUC=0.6192 | Val Acc=0.0987 F1=0.0026 AUC=nan\nEpoch 020 | Loss=4.6296 | Train Acc=0.1255 F1=0.0025 AUC=0.6634 | Val Acc=0.1277 F1=0.0025 AUC=nan\nEpoch 030 | Loss=4.3896 | Train Acc=0.1406 F1=0.0026 AUC=0.7098 | Val Acc=0.1425 F1=0.0026 AUC=nan\nEpoch 040 | Loss=4.0883 | Train Acc=0.1733 F1=0.0056 AUC=0.7585 | Val Acc=0.1769 F1=0.0057 AUC=nan\nEpoch 050 | Loss=3.8017 | Train Acc=0.2018 F1=0.0097 AUC=0.8092 | Val Acc=0.2039 F1=0.0098 AUC=nan\nEpoch 060 | Loss=3.5391 | Train Acc=0.2370 F1=0.0137 AUC=0.8519 | Val Acc=0.2379 F1=0.0134 AUC=nan\nEpoch 070 | Loss=3.3067 | Train Acc=0.2563 F1=0.0206 AUC=0.8847 | Val Acc=0.2551 F1=0.0198 AUC=nan\nEpoch 080 | Loss=3.1190 | Train Acc=0.2786 F1=0.0295 AUC=0.9075 | Val Acc=0.2781 F1=0.0288 AUC=nan\nEpoch 090 | Loss=2.9742 | Train Acc=0.2951 F1=0.0369 AUC=0.9217 | Val Acc=0.2956 F1=0.0368 AUC=nan\nEpoch 100 | Loss=2.8621 | Train Acc=0.3087 F1=0.0446 AUC=0.9316 | Val Acc=0.3113 F1=0.0443 AUC=nan\nEpoch 110 | Loss=2.7702 | Train Acc=0.3195 F1=0.0517 AUC=0.9391 | Val Acc=0.3213 F1=0.0519 AUC=nan\nEpoch 120 | Loss=2.6920 | Train Acc=0.3292 F1=0.0591 AUC=0.9450 | Val Acc=0.3315 F1=0.0591 AUC=nan\nEpoch 130 | Loss=2.6243 | Train Acc=0.3376 F1=0.0673 AUC=0.9498 | Val Acc=0.3391 F1=0.0670 AUC=nan\nEpoch 140 | Loss=2.5656 | Train Acc=0.3446 F1=0.0761 AUC=0.9538 | Val Acc=0.3472 F1=0.0768 AUC=nan\nEpoch 150 | Loss=2.5151 | Train Acc=0.3510 F1=0.0851 AUC=0.9570 | Val Acc=0.3546 F1=0.0850 AUC=nan\nEpoch 160 | Loss=2.4717 | Train Acc=0.3566 F1=0.0944 AUC=0.9597 | Val Acc=0.3603 F1=0.0937 AUC=nan\nEpoch 170 | Loss=2.4339 | Train Acc=0.3620 F1=0.1020 AUC=0.9619 | Val Acc=0.3656 F1=0.1021 AUC=nan\nEpoch 180 | Loss=2.4004 | Train Acc=0.3667 F1=0.1095 AUC=0.9637 | Val Acc=0.3724 F1=0.1123 AUC=nan\nEpoch 190 | Loss=2.3702 | Train Acc=0.3714 F1=0.1173 AUC=0.9653 | Val Acc=0.3768 F1=0.1208 AUC=nan\nEpoch 200 | Loss=2.3428 | Train Acc=0.3759 F1=0.1254 AUC=0.9668 | Val Acc=0.3819 F1=0.1294 AUC=nan\nModelos guardados para aggr=mean.\nMétricas guardadas: metrics_mean.csv\n\n=== Treino GraphSAGE heterogéneo com aggr=sum ===\nEpoch 010 | Loss=10832.7422 | Train Acc=0.0053 F1=0.0003 AUC=0.4999 | Val Acc=0.0050 F1=0.0002 AUC=nan\nEpoch 020 | Loss=5318.7070 | Train Acc=0.0077 F1=0.0007 AUC=0.5019 | Val Acc=0.0089 F1=0.0007 AUC=nan\nEpoch 030 | Loss=2772.4397 | Train Acc=0.0300 F1=0.0020 AUC=0.4992 | Val Acc=0.0301 F1=0.0021 AUC=nan\nEpoch 040 | Loss=1272.7180 | Train Acc=0.0416 F1=0.0026 AUC=0.5031 | Val Acc=0.0401 F1=0.0024 AUC=nan\nEpoch 050 | Loss=690.5239 | Train Acc=0.1084 F1=0.0054 AUC=0.5067 | Val Acc=0.1087 F1=0.0053 AUC=nan\nEpoch 060 | Loss=267.5119 | Train Acc=0.0984 F1=0.0057 AUC=0.5169 | Val Acc=0.0986 F1=0.0056 AUC=nan\nEpoch 070 | Loss=109.5715 | Train Acc=0.0964 F1=0.0085 AUC=0.5925 | Val Acc=0.0975 F1=0.0093 AUC=nan\nEpoch 080 | Loss=72.4372 | Train Acc=0.1119 F1=0.0120 AUC=0.6117 | Val Acc=0.1125 F1=0.0119 AUC=nan\nEpoch 090 | Loss=54.7789 | Train Acc=0.1259 F1=0.0145 AUC=0.6219 | Val Acc=0.1241 F1=0.0143 AUC=nan\nEpoch 100 | Loss=43.1119 | Train Acc=0.1418 F1=0.0163 AUC=0.6294 | Val Acc=0.1403 F1=0.0157 AUC=nan\nEpoch 110 | Loss=34.3103 | Train Acc=0.1411 F1=0.0169 AUC=0.6369 | Val Acc=0.1425 F1=0.0166 AUC=nan\nEpoch 120 | Loss=31.9122 | Train Acc=0.1405 F1=0.0197 AUC=0.6432 | Val Acc=0.1433 F1=0.0194 AUC=nan\nEpoch 130 | Loss=28.3012 | Train Acc=0.1521 F1=0.0213 AUC=0.6483 | Val Acc=0.1532 F1=0.0222 AUC=nan\nEpoch 140 | Loss=24.0524 | Train Acc=0.1523 F1=0.0232 AUC=0.6519 | Val Acc=0.1562 F1=0.0250 AUC=nan\nEpoch 150 | Loss=22.3026 | Train Acc=0.1487 F1=0.0243 AUC=0.6582 | Val Acc=0.1500 F1=0.0249 AUC=nan\nEpoch 160 | Loss=24.4861 | Train Acc=0.1450 F1=0.0216 AUC=0.6400 | Val Acc=0.1461 F1=0.0234 AUC=nan\nEpoch 170 | Loss=20.1987 | Train Acc=0.1530 F1=0.0240 AUC=0.6523 | Val Acc=0.1563 F1=0.0251 AUC=nan\nEpoch 180 | Loss=17.6948 | Train Acc=0.1610 F1=0.0265 AUC=0.6591 | Val Acc=0.1636 F1=0.0273 AUC=nan\nEpoch 190 | Loss=16.6091 | Train Acc=0.1612 F1=0.0289 AUC=0.6672 | Val Acc=0.1641 F1=0.0296 AUC=nan\nEpoch 200 | Loss=14.8722 | Train Acc=0.1749 F1=0.0327 AUC=0.6773 | Val Acc=0.1799 F1=0.0334 AUC=nan\nModelos guardados para aggr=sum.\nMétricas guardadas: metrics_sum.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results = {}\n",
    "\n",
    "for aggr in AGGREGATIONS:\n",
    "    print(f\"\\n=== Testing models using the aggregation {aggr} ===\")\n",
    "    \n",
    "    base_model = GraphSAGEEnc(num_features, 128, 128, aggr=aggr)\n",
    "    model_hetero = to_hetero(base_model, data_sub.metadata(), aggr=aggr).to(device)\n",
    "    head = nn.Linear(128, num_classes).to(device)\n",
    "    \n",
    "    # Load Weights of the models\n",
    "    model_hetero.load_state_dict(torch.load(f\"/kaggle/working/model_{aggr}.pth\"))\n",
    "    head.load_state_dict(torch.load(f\"/kaggle/working/head_{aggr}.pth\"))\n",
    "    \n",
    "    model_hetero.eval()\n",
    "    head.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h_dict = model_hetero(x_dict, edge_index_dict)\n",
    "        logits = head(h_dict[\"paper\"])\n",
    "        \n",
    "        # Calculate Metrics\n",
    "        test_acc, test_f1, test_auc = compute_metrics(logits[test_mask], y[test_mask])\n",
    "        \n",
    "    print(f\"Test Acc={test_acc:.4f} | Test F1={test_f1:.4f} | Test AUC={test_auc:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results[aggr] = {\n",
    "        \"acc\": test_acc,\n",
    "        \"f1\": test_f1,\n",
    "        \"auc\": test_auc\n",
    "    }\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-03T19:49:45.803900Z",
     "iopub.execute_input": "2025-12-03T19:49:45.804135Z",
     "iopub.status.idle": "2025-12-03T19:49:47.328298Z",
     "shell.execute_reply.started": "2025-12-03T19:49:45.804119Z",
     "shell.execute_reply": "2025-12-03T19:49:47.327428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\n=== Testando modelo mean ===\nTest Acc=0.3754 | Test F1=0.1254 | Test AUC=nan\n\n=== Testando modelo sum ===\nTest Acc=0.1791 | Test F1=0.0329 | Test AUC=nan\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 26
  }
 ]
}
